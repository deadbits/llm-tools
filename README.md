# llm-tools
Collection of tools to assist with using Large Large Models (LLM)

## Overview ðŸ“–
The ability to run an LLM on your home computer is a huge resource for productivity and development, among many, many other things. This repo contains a handful of one-off scripts and demos for interacting locally hosted LLMs, and some LangChain and LlamaIndex examples using OpenAI.


## Stack [WIP]
Running models and tools locally is all good and well, but pretty quickly you'll want a more robust stack for things like:

* Inference hosting
* Orchestration
* Retrieving data from external sources
* Providing access to external tools
* [Managing prompts](https://github.com/deadbits/prompt-serve)
* Application hosting
* Interaction via common applications (iMessage, Telegram, etc.)
* Maintain memory/history of past interactions
* Embeddings model
* Store vector embeddings and metadata
* Manage documents prior to embeddings creation
* Logging

The list below includes a few of my favorites:
* [prompt-serve](https://github.com/deadbits/prompt-serve)
* [LlamaIndex](https://github.com/jerryjliu/llama_index)
* [LangChain](https://python.langchain.com/docs/get_started/introduction.html)
* [ChromaDB](https://www.trychroma.com/)
* [FastChat](https://github.com/lm-sys/FastChat)
* [Gradio](https://www.gradio.app/)
* [OpenAI](https://openai.com/)
* [RedPajama](https://www.together.xyz/blog/redpajama-models-v1)
* [Mosaic ML](https://huggingface.co/mosaicml)
* [GPTCache](https://github.com/zilliztech/GPTCache)
* [Lambda Cloud](https://cloud.lambdalabs.com/)
* [Metal](https://getmetal.io/)
* [BentoML](https://github.com/ssheng/BentoChain)
* [Modal](https://modal.com/)
